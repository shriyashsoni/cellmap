# CellMap: AI-Powered Spatial Cellular Prediction from Histology Images

![ChatGPT Image May 8, 2025, 08_13_11 PM](https://github.com/user-attachments/assets/afb61a58-6951-40a1-b606-10ad358d75e8)


## Overview

This project aims to develop a deep learning model that can predict spatially-resolved cell-type compositions (35 classes) from Hematoxylin and Eosin (H&E) stained histology slides, using only visual features from the images. The solution bridges the gap between standard histological imaging and spatial transcriptomics, offering a low-cost and scalable method for deeper tissue characterization.

## Project Structure

\`\`\`
üìÅ CellMap
‚îú‚îÄ‚îÄ üìÑ dataset.py            # Data loading and preprocessing
‚îú‚îÄ‚îÄ üìÑ model.py              # Model architecture definitions
‚îú‚îÄ‚îÄ üìÑ train.py              # Training pipeline
‚îú‚îÄ‚îÄ üìÑ infer.py              # Inference and submission
‚îú‚îÄ‚îÄ üìÑ utils.py              # Visualization and analysis utilities
‚îú‚îÄ‚îÄ üìÑ README.md             # Project documentation
\`\`\`

## Installation

```bash
# Clone the repository
git clone https://github.com/shriyashsoni/cellmap.git
cd cellmap

# Install dependencies
pip install -r requirements.txt

### CellMap: AI-Powered Spatial Cellular Prediction from Histology Images

I'll help you build a comprehensive solution for the Global AI Hackathon'25 by Elucidata. Based on your requirements and the logo you've shared, I'll create a complete project structure with all the necessary components to predict spatial cellular organization from histology images.

## Project Overview

CellMap is a deep learning solution that predicts spatially-resolved cell-type compositions (35 classes) from H&E stained histology slides using only visual features from the images. This bridges the gap between standard histological imaging and spatial transcriptomics, offering a low-cost and scalable method for deeper tissue characterization.





## Project Structure

Let's build a complete end-to-end pipeline with the following components:

1. Data loading and preprocessing
2. Model architecture
3. Training pipeline
4. Inference and submission


Let's implement each component:

```python project="CellMap" file="dataset.py"
...
```

Now, let's implement the model architecture:

```python project="CellMap" file="model.py"
...
```

Now, let's implement the training pipeline:

```python project="CellMap" file="train.py"
...
```

Now, let's implement the inference and submission code:

```python project="CellMap" file="infer.py"
...
```

Finally, let's create a utility script for visualization and analysis:

```python project="CellMap" file="utils.py"
...
```

Let's also create a README file to explain how to use the project:

```python project="CellMap" file="README.md"
...
```

## Data

The data is provided in an H5 file format (`elucidata_ai_challenge_data.h5`) with the following structure:

- `images`: H&E stained histology images for each slide
- `spatial_coords`: Coordinates of spots on each slide
- `cell_abundance`: Cell type abundances for each spot (training data)


## Usage

### Data Exploration

```shellscript
# Visualize dataset and analyze cell type distributions
python utils.py
```

### Training

```shellscript
# Train a single-scale model
python train.py --data_path elucidata_ai_challenge_data.h5 --model_type single --backbone resnet50 --num_epochs 50

# Train a multi-scale model
python train.py --data_path elucidata_ai_challenge_data.h5 --model_type multi_scale --backbone efficientnet_b0 --num_epochs 50
```

### Inference and Submission

```shellscript
# Generate predictions and create submission file
python infer.py --data_path elucidata_ai_challenge_data.h5 --checkpoint_path checkpoints/best_model.pth --visualize
```

## Model Architecture

The project implements several model architectures:

1. **Single-Scale CNN**: Uses a pre-trained backbone (ResNet50, EfficientNet, DenseNet) with a regression head to predict cell type abundances.
2. **Multi-Scale CNN**: Processes images at different scales to capture both local and global tissue context.
3. **Ensemble Model**: Combines predictions from multiple models for improved performance.


## Key Features

- **Stain Normalization**: Implements Macenko method for H&E stain normalization.
- **Custom Loss Function**: Combines MSE and Spearman correlation for better training.
- **Visualization Tools**: Includes heatmap visualization, feature space analysis, and Grad-CAM for model interpretability.
- **Efficient Data Pipeline**: Optimized for handling large histology images and spot-level predictions.


## Results

The model achieves high Spearman correlation scores across test spots, demonstrating its ability to generalize to unseen tissue slides. Visualizations show biologically plausible spatial distributions of cell types.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgements

- Global AI Hackathon'25 by Elucidata for providing the challenge and dataset
- The spatial transcriptomics community for advancing this important field


## Contact

For any questions or feedback, please open an issue or contact [[your-email@example.com](apnacoding.tech@gmail.com)].

